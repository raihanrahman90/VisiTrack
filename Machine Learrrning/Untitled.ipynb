{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b75986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==1.*\n",
      "ERROR: No matching distribution found for tensorflow==1.*\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f4a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\asus\\anaconda3\\lib\\site-packages (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipykernel) (5.0.5)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipykernel) (6.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipykernel) (6.1.12)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipykernel) (7.22.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (3.0.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (52.0.0.post20210125)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.17.2)\n",
      "Requirement already satisfied: pygments in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (2.8.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (5.0.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\asus\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\asus\\anaconda3\\lib\\site-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel) (20.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel) (2.8.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel) (4.7.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel) (227)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel) (1.15.0)\n",
      "Installed kernelspec envTraining in C:\\Users\\Asus\\AppData\\Roaming\\jupyter\\kernels\\envtraining\n"
     ]
    }
   ],
   "source": [
    "!pip install --user ipykernel\n",
    "!python -m ipykernel install --user --name=envTraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d069d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-10723574f885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_reader_builder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\object_detection\\legacy\\trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstandard_fields\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutil_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariables_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdeployment\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_deploy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\object_detection\\utils\\variables_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariables\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mslim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e190b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')\n",
    "flags.DEFINE_integer('task', 0, 'task id')\n",
    "flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')\n",
    "flags.DEFINE_boolean('clone_on_cpu', False,\n",
    "                     'Force clones to be deployed on CPU.  Note that even if '\n",
    "                     'set to False (allowing ops to run on gpu), some ops may '\n",
    "                     'still be run on the CPU if they have no GPU kernel.')\n",
    "flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '\n",
    "                     'replicas.')\n",
    "flags.DEFINE_integer('ps_tasks', 0,\n",
    "                     'Number of parameter server tasks. If None, does not use '\n",
    "                     'a parameter server.')\n",
    "flags.DEFINE_string('train_dir', '',\n",
    "                    'Directory to save the checkpoints and training summaries.')\n",
    "\n",
    "flags.DEFINE_string('pipeline_config_path', '',\n",
    "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
    "                    'file. If provided, other configs are ignored')\n",
    "\n",
    "flags.DEFINE_string('train_config_path', '',\n",
    "                    'Path to a train_pb2.TrainConfig config file.')\n",
    "flags.DEFINE_string('input_config_path', '',\n",
    "                    'Path to an input_reader_pb2.InputReader config file.')\n",
    "flags.DEFINE_string('model_config_path', '',\n",
    "                    'Path to a model_pb2.DetectionModel config file.')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  assert FLAGS.train_dir, '`train_dir` is missing.'\n",
    "  if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "  if FLAGS.pipeline_config_path:\n",
    "    configs = config_util.get_configs_from_pipeline_file(\n",
    "        FLAGS.pipeline_config_path)\n",
    "    if FLAGS.task == 0:\n",
    "      tf.gfile.Copy(FLAGS.pipeline_config_path,\n",
    "                    os.path.join(FLAGS.train_dir, 'pipeline.config'),\n",
    "                    overwrite=True)\n",
    "  else:\n",
    "    configs = config_util.get_configs_from_multiple_files(\n",
    "        model_config_path=FLAGS.model_config_path,\n",
    "        train_config_path=FLAGS.train_config_path,\n",
    "        train_input_config_path=FLAGS.input_config_path)\n",
    "    if FLAGS.task == 0:\n",
    "      for name, config in [('model.config', FLAGS.model_config_path),\n",
    "                           ('train.config', FLAGS.train_config_path),\n",
    "                           ('input.config', FLAGS.input_config_path)]:\n",
    "        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),\n",
    "                      overwrite=True)\n",
    "\n",
    "  model_config = configs['model']\n",
    "  train_config = configs['train_config']\n",
    "  input_config = configs['train_input_config']\n",
    "\n",
    "  model_fn = functools.partial(\n",
    "      model_builder.build,\n",
    "      model_config=model_config,\n",
    "      is_training=True)\n",
    "\n",
    "  create_input_dict_fn = functools.partial(\n",
    "      input_reader_builder.build, input_config)\n",
    "\n",
    "  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "  cluster_data = env.get('cluster', None)\n",
    "  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
    "  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
    "  task_info = type('TaskSpec', (object,), task_data)\n",
    "\n",
    "  # Parameters for a single worker.\n",
    "  ps_tasks = 0\n",
    "  worker_replicas = 1\n",
    "  worker_job_name = 'lonely_worker'\n",
    "  task = 0\n",
    "  is_chief = True\n",
    "  master = ''\n",
    "\n",
    "  if cluster_data and 'worker' in cluster_data:\n",
    "    # Number of total worker replicas include \"worker\"s and the \"master\".\n",
    "    worker_replicas = len(cluster_data['worker']) + 1\n",
    "  if cluster_data and 'ps' in cluster_data:\n",
    "    ps_tasks = len(cluster_data['ps'])\n",
    "\n",
    "  if worker_replicas > 1 and ps_tasks < 1:\n",
    "    raise ValueError('At least 1 ps task is needed for distributed training.')\n",
    "\n",
    "  if worker_replicas >= 1 and ps_tasks > 0:\n",
    "    # Set up distributed training.\n",
    "    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
    "                             job_name=task_info.type,\n",
    "                             task_index=task_info.index)\n",
    "    if task_info.type == 'ps':\n",
    "      server.join()\n",
    "      return\n",
    "\n",
    "    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
    "    task = task_info.index\n",
    "    is_chief = (task_info.type == 'master')\n",
    "    master = server.target\n",
    "\n",
    "  trainer.train(create_input_dict_fn, model_fn, train_config, master, task,\n",
    "                FLAGS.num_clones, worker_replicas, FLAGS.clone_on_cpu, ps_tasks,\n",
    "                worker_job_name, is_chief, FLAGS.train_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
